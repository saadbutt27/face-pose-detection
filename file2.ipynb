{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f9ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d62c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 face, 176.7ms\n",
      "Speed: 8.4ms preprocess, 176.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Head Pose Angles - Pitch: -179.68621664002237, Yaw: -4.327508036987097, Roll: 2.739224906538276\n",
      "Head: Looking up/down | Gaze: Looking Center\n"
     ]
    }
   ],
   "source": [
    "# Load image\n",
    "image_path = './images/4.jpg'  # Replace with your image path\n",
    "frame = cv2.imread(image_path)\n",
    "if frame is None:\n",
    "    print(\"Error: Cannot load image.\")\n",
    "    exit()\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n-face-lindevs.pt\")\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True,\n",
    "                                  max_num_faces=1,\n",
    "                                  refine_landmarks=True,\n",
    "                                  min_detection_confidence=0.5)\n",
    "\n",
    "def get_head_pose(image, landmarks):\n",
    "    image_points = np.array([\n",
    "        landmarks[1],    # Nose tip\n",
    "        landmarks[152],  # Chin\n",
    "        landmarks[263],  # Right eye right corner\n",
    "        landmarks[33],   # Left eye left corner\n",
    "        landmarks[287],  # Right mouth corner\n",
    "        landmarks[57]    # Left mouth corner\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),\n",
    "        (0.0, -330.0, -65.0),\n",
    "        (225.0, 170.0, -135.0),\n",
    "        (-225.0, 170.0, -135.0),\n",
    "        (150.0, -150.0, -125.0),\n",
    "        (-150.0, -150.0, -125.0)\n",
    "    ])\n",
    "\n",
    "    focal_length = image.shape[1]\n",
    "    center = (image.shape[1] / 2, image.shape[0] / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    success, rvec, _, _ = cv2.solvePnPRansac(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "\n",
    "    rmat, _ = cv2.Rodrigues(rvec)\n",
    "    proj_matrix = np.hstack((rmat, np.zeros((3, 1))))\n",
    "    _, _, _, _, _, _, angles = cv2.decomposeProjectionMatrix(proj_matrix)\n",
    "\n",
    "    return angles  # pitch, yaw, roll\n",
    "\n",
    "def get_eye_direction(landmarks, iw):\n",
    "    left_eye = landmarks[33]\n",
    "    right_eye = landmarks[263]\n",
    "    eye_mid_x = (left_eye[0] + right_eye[0]) / 2\n",
    "    eye_mid_x_norm = eye_mid_x / iw\n",
    "\n",
    "    if eye_mid_x_norm < 0.4:\n",
    "        return \"Looking Left\"\n",
    "    elif eye_mid_x_norm > 0.6:\n",
    "        return \"Looking Right\"\n",
    "    else:\n",
    "        return \"Looking Center\"\n",
    "\n",
    "# Run YOLO face detection\n",
    "results = model(frame)\n",
    "\n",
    "for box in results[0].boxes.xyxy:\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    face = frame[y1:y2, x1:x2]\n",
    "\n",
    "    if face.shape[0] == 0 or face.shape[1] == 0:\n",
    "        continue\n",
    "\n",
    "    face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    result_mesh = face_mesh.process(face_rgb)\n",
    "\n",
    "    if result_mesh.multi_face_landmarks:\n",
    "        for landmarks in result_mesh.multi_face_landmarks:\n",
    "            ih, iw, _ = face.shape\n",
    "            coords = [(int(p.x * iw), int(p.y * ih)) for p in landmarks.landmark]\n",
    "\n",
    "            # Visualize key landmarks for debugging (relative to face bounding box)\n",
    "            for i, landmark in enumerate(coords):\n",
    "                x, y = landmark\n",
    "                cv2.circle(frame, (x1 + x, y1 + y), 5, (0, 0, 255), -1)  # Map to original frame coordinates\n",
    "\n",
    "            try:\n",
    "                # Get head pose angles\n",
    "                angles = get_head_pose(face, coords)\n",
    "                pitch, yaw, roll = [a[0] for a in angles]\n",
    "                print(f\"Head Pose Angles - Pitch: {pitch}, Yaw: {yaw}, Roll: {roll}\")  # Debugging angles\n",
    "\n",
    "                # Adjust thresholds for pitch and yaw if needed\n",
    "                if abs(yaw) > 20:\n",
    "                    head_status = \"Head turned\"\n",
    "                elif abs(pitch) > 20:\n",
    "                    head_status = \"Looking up/down\"\n",
    "                else:\n",
    "                    head_status = \"Head OK\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error in head pose estimation: {e}\")\n",
    "                head_status = \"Head Pose Error\"\n",
    "\n",
    "            # Eye gaze check\n",
    "            eye_dir = get_eye_direction(coords, iw)\n",
    "\n",
    "            # Display all status info\n",
    "            print(f\"Head: {head_status} | Gaze: {eye_dir}\")\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw head status above the face box\n",
    "            cv2.putText(frame, head_status, (x1, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw eye direction below the face box\n",
    "            cv2.putText(frame, eye_dir, (x1, y2 + 20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6, (255, 255, 0), 2)\n",
    "\n",
    "# Save the final image\n",
    "cv2.imwrite(\"output_with_boxes.jpg\", frame)\n",
    "\n",
    "# Display result\n",
    "cv2.imshow(\"Image Pose & Gaze Detection\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
